{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 302603,
     "status": "ok",
     "timestamp": 1524621115670,
     "user": {
      "displayName": "Abhishek Kumar",
      "photoUrl": "//lh6.googleusercontent.com/-1IIri8PuptI/AAAAAAAAAAI/AAAAAAAAElE/RMgSD-7u2Z4/s50-c-k-no/photo.jpg",
      "userId": "108365469511301265401"
     },
     "user_tz": 240
    },
    "id": "Oc44HjsnS5SG",
    "outputId": "05478a81-d1ff-49fd-d57a-481642e79c1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Pandora_18k.zip', <httplib.HTTPMessage instance at 0x7f9e9a4393f8>)"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "urllib.urlretrieve (\"http://imag.pub.ro/pandora/Download/Pandora_18k.zip\", \"Pandora_18k.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "c82ewsRbXAf7"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('Pandora_18k.zip', 'r')\n",
    "zip_ref.extractall(\"./Pandora_18k\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1611,
     "status": "ok",
     "timestamp": 1524632052998,
     "user": {
      "displayName": "Abhishek Kumar",
      "photoUrl": "//lh6.googleusercontent.com/-1IIri8PuptI/AAAAAAAAAAI/AAAAAAAAElE/RMgSD-7u2Z4/s50-c-k-no/photo.jpg",
      "userId": "108365469511301265401"
     },
     "user_tz": 240
    },
    "id": "xOF1gmybXgzs",
    "outputId": "a60fdc3c-e5dc-4d7a-8e5d-a327a706f914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.9G\r\n",
      "drwxr-xr-x  1 root root 4.0K Apr 25 04:41 .\r\n",
      "drwxr-xr-x  1 root root 4.0K Apr 25 01:41 ..\r\n",
      "drwx------  4 root root 4.0K Apr 25 01:46 .cache\r\n",
      "drwxr-xr-x  3 root root 4.0K Apr 25 01:46 .config\r\n",
      "-rw-r--r--  1 root root 159M Apr 25 01:55 CustomVGG.h5\r\n",
      "drwxr-xr-x  1 root root 4.0K Apr 25 04:41 datalab\r\n",
      "drwxr-xr-x  4 root root 4.0K Apr 25 01:42 .forever\r\n",
      "drwxr-xr-x  2 root root 4.0K Apr 25 04:49 .gsutil\r\n",
      "drwxr-xr-x  5 root root 4.0K Apr 25 01:46 .ipython\r\n",
      "drwxr-xr-x  2 root root 4.0K Apr 25 01:57 .jupyter\r\n",
      "drwxr-xr-x  3 root root 4.0K Apr 25 01:55 .keras\r\n",
      "drwx------  3 root root 4.0K Apr 25 01:42 .local\r\n",
      "drwx------  3 root root 4.0K Apr 25 01:55 .nv\r\n",
      "drwxr-xr-x 20 root root 4.0K Apr 25 01:52 Pandora_18k\r\n",
      "drwxr-xr-x 20 root root 4.0K Apr 25 01:52 Pandora_18k_merged\r\n",
      "-rw-r--r--  1 root root 1.4G Apr 25 01:51 Pandora_18k.zip\r\n",
      "-rw-------  1 root root 1.0K Apr 25 01:42 .rnd\r\n",
      "-rw-r--r--  1 root root 7.6M Apr 25 04:05 try1-dataset.sav\r\n",
      "-rw-r--r--  1 root root 159M Apr 25 03:58 try1_weights.h5\r\n",
      "-rw-r--r--  1 root root 147M Apr 25 04:25 try1_weights.h5.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alh\n",
    "#!zip try1_weights.h5.zip try1_weights.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Vl8AT4v2ZK3v"
   },
   "outputs": [],
   "source": [
    "datapath = './Pandora_18k'\n",
    "mergedDatapath = './Pandora_18k_merged'\n",
    "os.system(\"mkdir \"+mergedDatapath)\n",
    "def preprocess1():\n",
    "    d = datapath\n",
    "    dirsNames = [o for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "    dirs = [os.path.join(d,o) for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "    #print dirs\n",
    "\n",
    "    # move all images from subfolders to a single folder. Ignore some naming conflicts\n",
    "    for i in xrange(len(dirs)):\n",
    "        mergedPath = mergedDatapath + '/' + dirsNames[i] + \"_merged\"\n",
    "        os.system(\"mkdir \"+mergedPath)\n",
    "        os.system(\"find \"+dirs[i]+\"  -iname '*.jpg' -exec cp -f -t \"+mergedPath+\"  '{}' +\")\n",
    "        #if i > 1: break\n",
    "preprocess1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 780
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4290977,
     "status": "ok",
     "timestamp": 1524628684136,
     "user": {
      "displayName": "Abhishek Kumar",
      "photoUrl": "//lh6.googleusercontent.com/-1IIri8PuptI/AAAAAAAAAAI/AAAAAAAAElE/RMgSD-7u2Z4/s50-c-k-no/photo.jpg",
      "userId": "108365469511301265401"
     },
     "user_tz": 240
    },
    "id": "kpraXWdGQUi4",
    "outputId": "dac0f583-5e84-498c-8447-db2f85a976a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14278,) (3570,)\n",
      "Traing the custom model\n",
      "Epoch 1/20\n",
      "650/650 [==============================] - 215s 331ms/step - loss: 6.4100 - acc: 0.2970 - val_loss: 2.4420 - val_acc: 0.3256\n",
      "Epoch 2/20\n",
      " 49/650 [=>............................] - ETA: 2:38 - loss: 2.2343 - acc: 0.4214650/650 [==============================] - 214s 330ms/step - loss: 1.8822 - acc: 0.4719 - val_loss: 2.0172 - val_acc: 0.3736\n",
      "Epoch 3/20\n",
      "236/650 [=========>....................] - ETA: 1:49 - loss: 1.5059 - acc: 0.5447650/650 [==============================] - 214s 330ms/step - loss: 1.4020 - acc: 0.5771 - val_loss: 1.9332 - val_acc: 0.3915\n",
      "Epoch 4/20\n",
      "306/650 [=============>................] - ETA: 1:30 - loss: 1.1604 - acc: 0.6456650/650 [==============================] - 215s 330ms/step - loss: 1.0794 - acc: 0.6680 - val_loss: 1.9102 - val_acc: 0.4173\n",
      "Epoch 5/20\n",
      "332/650 [==============>...............] - ETA: 1:24 - loss: 0.9334 - acc: 0.7047650/650 [==============================] - 215s 331ms/step - loss: 0.8909 - acc: 0.7205 - val_loss: 1.8884 - val_acc: 0.4261\n",
      "Epoch 6/20\n",
      "342/650 [==============>...............] - ETA: 1:21 - loss: 0.7591 - acc: 0.7654650/650 [==============================] - 215s 331ms/step - loss: 0.7182 - acc: 0.7736 - val_loss: 1.9804 - val_acc: 0.4372\n",
      "Epoch 7/20\n",
      "345/650 [==============>...............] - ETA: 1:20 - loss: 0.6286 - acc: 0.8020650/650 [==============================] - 215s 330ms/step - loss: 0.5983 - acc: 0.8102 - val_loss: 1.9291 - val_acc: 0.4457\n",
      "Epoch 8/20\n",
      "346/650 [==============>...............] - ETA: 1:20 - loss: 0.5217 - acc: 0.8332650/650 [==============================] - 215s 330ms/step - loss: 0.5184 - acc: 0.8364 - val_loss: 1.9686 - val_acc: 0.4452\n",
      "Epoch 9/20\n",
      "347/650 [===============>..............] - ETA: 1:20 - loss: 0.4460 - acc: 0.8599650/650 [==============================] - 215s 331ms/step - loss: 0.4255 - acc: 0.8658 - val_loss: 1.9810 - val_acc: 0.4511\n",
      "Epoch 10/20\n",
      "346/650 [==============>...............] - ETA: 1:20 - loss: 0.3738 - acc: 0.8795650/650 [==============================] - 215s 330ms/step - loss: 0.3590 - acc: 0.8858 - val_loss: 1.9921 - val_acc: 0.4642\n",
      "Epoch 11/20\n",
      "345/650 [==============>...............] - ETA: 1:20 - loss: 0.3123 - acc: 0.9017650/650 [==============================] - 215s 330ms/step - loss: 0.3171 - acc: 0.8993 - val_loss: 2.1044 - val_acc: 0.4372\n",
      "Epoch 12/20\n",
      "345/650 [==============>...............] - ETA: 1:20 - loss: 0.2862 - acc: 0.9128650/650 [==============================] - 215s 331ms/step - loss: 0.2740 - acc: 0.9158 - val_loss: 2.0847 - val_acc: 0.4548\n",
      "Epoch 13/20\n",
      "345/650 [==============>...............] - ETA: 1:20 - loss: 0.2528 - acc: 0.9181650/650 [==============================] - 215s 330ms/step - loss: 0.2474 - acc: 0.9205 - val_loss: 2.1308 - val_acc: 0.4446\n",
      "Epoch 14/20\n",
      "345/650 [==============>...............] - ETA: 1:20 - loss: 0.2370 - acc: 0.9272650/650 [==============================] - 214s 329ms/step - loss: 0.2340 - acc: 0.9297 - val_loss: 2.1365 - val_acc: 0.4608\n",
      "Epoch 15/20\n",
      "345/650 [==============>...............] - ETA: 1:20 - loss: 0.2013 - acc: 0.9365650/650 [==============================] - 214s 329ms/step - loss: 0.1996 - acc: 0.9379 - val_loss: 2.1023 - val_acc: 0.4622\n",
      "Epoch 16/20\n",
      "345/650 [==============>...............] - ETA: 1:20 - loss: 0.2067 - acc: 0.9364650/650 [==============================] - 214s 329ms/step - loss: 0.1938 - acc: 0.9406 - val_loss: 2.1496 - val_acc: 0.4577\n",
      "Epoch 17/20\n",
      "345/650 [==============>...............] - ETA: 1:20 - loss: 0.1804 - acc: 0.9470650/650 [==============================] - 214s 329ms/step - loss: 0.1758 - acc: 0.9478 - val_loss: 2.2054 - val_acc: 0.4574\n",
      "Epoch 18/20\n",
      "345/650 [==============>...............] - ETA: 1:20 - loss: 0.1534 - acc: 0.9533650/650 [==============================] - 214s 329ms/step - loss: 0.1502 - acc: 0.9547 - val_loss: 2.1289 - val_acc: 0.4739\n",
      "Epoch 19/20\n",
      "345/650 [==============>...............] - ETA: 1:20 - loss: 0.1325 - acc: 0.9575650/650 [==============================] - 214s 329ms/step - loss: 0.1328 - acc: 0.9580 - val_loss: 2.1679 - val_acc: 0.4776\n",
      "Epoch 20/20\n",
      "345/650 [==============>...............] - ETA: 1:20 - loss: 0.1364 - acc: 0.9620650/650 [==============================] - 214s 328ms/step - loss: 0.1336 - acc: 0.9621 - val_loss: 2.2409 - val_acc: 0.4662\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#from baseline import *\n",
    "\n",
    "mergedDatapath = './Pandora_18k_merged'\n",
    "img_width,img_height = 224,224\n",
    "\n",
    "def createCustomModel(num_classes=18):\n",
    "    VGG_model_path = \"VGG16_original.h5\"\n",
    "    #model = VGG16(input_shape = (img_width, img_height, 3))\n",
    "    #model = load_model(VGG_model_path)\n",
    "    model = VGG16()\n",
    "    \"\"\"\n",
    "    image = load_img('239.jpg', target_size=(224, 224))\n",
    "    # convert the image pixels to a numpy array\n",
    "    image = img_to_array(image)\n",
    "    # reshape data for the model\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    # prepare the image for the VGG model\n",
    "    image = preprocess_input(image)\n",
    "    # predict the probability across all output classes\n",
    "    yhat = model.predict(image)\n",
    "    # convert the probabilities to class labels\n",
    "    label = decode_predictions(yhat)\n",
    "    # retrieve the most likely result, e.g. highest probability\n",
    "    label = label[0][0]\n",
    "    # print the classification\n",
    "    print('%s (%.2f%%)' % (label[1], label[2]*100))\n",
    "    \"\"\"\n",
    "\n",
    "    #model.layers.pop()\n",
    "    x = model.layers[-5].output # dis regard the fc layers after this\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # creating the final model \n",
    "    model_final = Model(input = model.input, output = predictions)\n",
    "        #Total 24 layers,16 with weights\n",
    "    \"\"\"\n",
    "    [<keras.engine.topology.InputLayer at 0x7f0eb73f48d0>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb73f4a90>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb73f4ad0>,\n",
    "     <keras.layers.pooling.MaxPooling2D at 0x7f0eb73f4b50>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb73f4e90>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb73f4ed0>,\n",
    "     <keras.layers.pooling.MaxPooling2D at 0x7f0eb73f4fd0>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb639e150>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb639e190>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb639e290>,\n",
    "     <keras.layers.pooling.MaxPooling2D at 0x7f0eb639e390>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb639e4d0>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb639e510>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb639e610>,\n",
    "     <keras.layers.pooling.MaxPooling2D at 0x7f0eb639e710>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb639e850>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb639e890>,\n",
    "     <keras.layers.convolutional.Conv2D at 0x7f0eb639e990>,\n",
    "     <keras.layers.pooling.MaxPooling2D at 0x7f0eb639ea90>,  #19 till here freezing\n",
    "     <keras.layers.core.Flatten at 0x7f0eb4e3c3d0>,\n",
    "     <keras.layers.core.Dense at 0x7f0eb4e3c2d0>,\n",
    "     <keras.layers.core.Dropout at 0x7f0eb4e3c050>,\n",
    "     <keras.layers.core.Dense at 0x7f0eb4e64410>,\n",
    "     <keras.layers.core.Dense at 0x7f0eb4e64390>]\n",
    "    \"\"\"\n",
    "    for layer in model.layers[:19]:\n",
    "        layer.trainable = False\n",
    "    # compile the model \n",
    "    model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "    print model_final.summary()\n",
    "    model_final.save(\"./CustomVGG.h5\")\n",
    "    return model_final\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getDataset(perClassCount = -1, size=(500,500)):\n",
    "    \n",
    "    pkfilename =  './' + 'feature_images_keras.sav'\n",
    "    \n",
    "    d = mergedDatapath\n",
    "    dirsNames = [o for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "    dirs = [os.path.join(d,o) for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "\n",
    "    np.random.seed(0)\n",
    "    X,Y= [],[]\n",
    "    for i in range(len(dirs)):\n",
    "        d = dirs[i]\n",
    "        filenames = glob.glob(d+'/*.jpg')\n",
    "        l = len(filenames)\n",
    "\n",
    "        if perClassCount == -1 : # take all data\n",
    "            X += filenames\n",
    "            Y += [i for j in xrange(len(filenames))]\n",
    "        else:\n",
    "            f = list(np.random.choice(filenames,replace=False,size=np.min(perClassCount,len(filenames))))\n",
    "            X += f\n",
    "            Y += [i for j in xrange(perClassCount)] # label of these images\n",
    "        \n",
    "\n",
    "    print(\"Reading images...\")\n",
    "    images = []\n",
    "    j = 0\n",
    "    for i in range(len(X)):\n",
    "        images.append(img_to_array(load_img(X[i], target_size=size)))\n",
    "        if len(images) > 17000 : break\n",
    "        if (i+1)%500==0:\n",
    "            print \"Read \",i+1,\" images.\"\n",
    "    print \"Done reading images...\"\n",
    "    images=np.array(images) \n",
    "    images=preprocess_input(images)\n",
    "    print \"Done processing images...\"\n",
    "    X = images\n",
    "    print \"Dumping the features for later use..\"\n",
    "    \n",
    "    Y= keras.utils.to_categorical(np.array(Y),18)\n",
    "    pickle.dump((X,Y), open(pkfilename, 'wb'))\n",
    "\n",
    "    return X,Y\n",
    "\n",
    "def getDataset2():\n",
    "    '''returns only the files name and not the actual images'''\n",
    "    d = mergedDatapath\n",
    "    dirsNames = [o for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "    dirs = [os.path.join(d,o) for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "\n",
    "    X,Y= [],[]\n",
    "    for i in range(len(dirs)):\n",
    "        d = dirs[i]\n",
    "        filenames = glob.glob(d+'/*.jpg')\n",
    "        l = len(filenames)\n",
    "\n",
    "        X += filenames\n",
    "        Y += [i for j in xrange(len(filenames))]\n",
    "    \n",
    "    l = len(X)\n",
    "    X= np.array(X)\n",
    "    Y=np.array(Y)\n",
    "    return train_test_split(X,Y,test_size=0.2)\n",
    "'''\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return np.array([\n",
    "            resize(imread(file_name), (200, 200))\n",
    "               for file_name in batch_x]), np.array(batch_y)\n",
    "'''\n",
    "\n",
    "def DataGenerator(X,Y,size=(224,224),batch_size=20):\n",
    "    \n",
    "    \n",
    "\n",
    "    while 1:\n",
    "\n",
    "      idxs = np.random.choice(X.shape[0],replace=False,size=batch_size)\n",
    "      images = []\n",
    "      for i in idxs:\n",
    "        images.append(img_to_array(load_img(X[i], target_size=size)))\n",
    "      images=np.array(images) \n",
    "      images=preprocess_input(images)\n",
    "      yield images,keras.utils.to_categorical(np.array(Y[idxs]),18) # yield image and label pair\n",
    "\n",
    "       \n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    trainx,testx, trainy ,testy = getDataset2()\n",
    "    print trainx.shape, testx.shape\n",
    "  \n",
    "    #model = createCustomModel()\n",
    "    model = load_model(\"./CustomVGG.h5\")\n",
    "    #print model.summary()\n",
    "    \n",
    "    \"\"\"\n",
    "    X,Y = getDataset(perClassCount = -1,size=(img_width, img_height))\n",
    "    trainx,testx, trainy ,testy = train_test_split(X,Y,test_size=0.2)\n",
    "    print trainx.shape, testx.shape\n",
    "    \"\"\"\n",
    "    \n",
    "    print \"Traing the custom model\"\n",
    "    batch = 20\n",
    "    #model.fit(trainx, trainy,batch_size=batch,nb_epoch=20,shuffle=True,verbose=1,validation_data=(testx, testy))\n",
    "    model.fit_generator(DataGenerator(trainx,trainy,batch_size=batch),epochs=20,steps_per_epoch=650,verbose=1,validation_data=DataGenerator(testx,testy,batch_size=batch),validation_steps=176)\n",
    "    model.save_weights(\"./try1_weights.h5\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10305,
     "status": "ok",
     "timestamp": 1524632180518,
     "user": {
      "displayName": "Abhishek Kumar",
      "photoUrl": "//lh6.googleusercontent.com/-1IIri8PuptI/AAAAAAAAAAI/AAAAAAAAElE/RMgSD-7u2Z4/s50-c-k-no/photo.jpg",
      "userId": "108365469511301265401"
     },
     "user_tz": 240
    },
    "id": "ciF3HLBz-Ilb",
    "outputId": "2c6745b4-b2de-421f-da83-f8e6206732a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Creating gs://colab-sample-bucket-f9cdd672-4844-11e8-be26-0242ac110002/...\n",
      "Copying file://try1_weights.h5 [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "/\n",
      "Operation completed over 1 objects/158.3 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import uuid\n",
    "from google.colab import auth\n",
    "#pickle.dump((trainx,testx, trainy ,testy), open(\"try1-dataset.sav\", 'wb'))\n",
    "#files.download(\"try1-dataset.sav\")\n",
    "#files.download(\"try1_weights.h5.zip\")\n",
    "\n",
    "def fileUploadToGCS(filepath):\n",
    "  auth.authenticate_user()\n",
    "  project_id = 'put your project id here'\n",
    "  !gcloud config set project {project_id}\n",
    "\n",
    "  # Make a unique bucket to which we'll upload the file.\n",
    "  # (GCS buckets are part of a single global namespace.)\n",
    "  bucket_name = 'colab-sample-bucket-' + str(uuid.uuid1())\n",
    "\n",
    "  # Full reference: https://cloud.google.com/storage/docs/gsutil/commands/mb\n",
    "  !gsutil mb gs://{bucket_name}\n",
    "  # Copy the file to our new bucket.\n",
    "  # Full reference: https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
    "  !gsutil cp try1_weights.h5 gs://{bucket_name}/\n",
    "fileUploadToGCS(\"./try1_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "NBr_GYfxQa_q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "682-Neural-Project.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
